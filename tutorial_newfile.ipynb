{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da16986-b620-4d9e-8d0d-d669d7c8ccf5",
   "metadata": {},
   "source": [
    "# Analysis with Coffea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ced43-27c1-42a1-9f1e-7aeecf73c406",
   "metadata": {},
   "source": [
    "<h2>Authors</h2>\n",
    "<b>Notebook by:</b> Mat Adamec (<i>UNL</i>)\n",
    "<br/>\n",
    "<br/>\n",
    "<b>coffea:</b>\n",
    "<br/>\n",
    "<a href=\"https://doi.org/10.5281/zenodo.6335374\"><img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.6335374.svg\" alt=\"DOI\"></a>\n",
    "<br/>\n",
    "    <ul>\n",
    "        <li>Lindsey Gray, Matteo Cremonesi, Bo Jayatilaka, Oliver Gutsche, Nick Smith, Allison Hall, Kevin Pedro, Maria Acosta <i>(FNAL)</i>; Andrew Melo <i>(Vanderbilt)</i>; Stefano Belforte <i>(INFN)</i>; and others</li>\n",
    "        <li>In collaboration with IRIS-HEP members: Jim Pivarski <i>(Princeton)</i>, Ben Galewsky <i>(NCSA)</i>, Mark Neubauer <i>(UIUC)</i></li>\n",
    "        <br/>\n",
    "    </ul>\n",
    "<b><a href=\"https://github.com/CoffeaTeam/coffea-casa\">coffea-casa</a>:</b>\n",
    "    <ul>\n",
    "        <li>Ken Bloom, Oksana Shadura <i>(UNL)</i>; Garhan Attebury, Carl Lundstedt, Derek Weitzel <i>(UNL-HCC)</i>; Mátyás Selmeci <i>(UWM)</i>; Brian Bockelman <i>(Morgridge Institute)</i></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3dfb9b-5318-4bef-beb4-217d400722ab",
   "metadata": {},
   "source": [
    "## What is Coffea?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2930e50-b560-4200-adea-94513b1a860d",
   "metadata": {},
   "source": [
    "Coffea stands for *Columnar Object Framework For Effective Analysis.* It contains a variety of tools which help physicists perform their analyses in a columnar fashion. By \"a columnar fashion,\" we mean that data is contained in numpy-like arrays upon which we can perform operations without calling an explicit event loop. Coffea is built on Awkward arrays and any Awkward operation can be done in a Coffea analysis. Beyond this, Coffea's analysis features can be broken into roughly four categories:\n",
    "\n",
    "* **NanoEvents** turns data into an Awkward array wrapped with a schema. The schema serves a variety of purposes, from enabling us to interpret data as physics objects (e.g., LorentzVectors) to handling the nesting of our fields and creating relevant physical cross-references. In short: NanoEvents makes our data act nicely in the context of a physics analysis. A schema can be made for any ntuple file.\n",
    "\n",
    "* **Hists** permit the plotting of ROOT-like histograms with Coffea.\n",
    "\n",
    "* **Processors** are Coffea's way of encapsulating an analysis in a way that is deployment-neutral. Once you have a Coffea analysis, you can throw it into a processor and use any of a variety of executors (e.g. Dask, Parsl, Spark) to chunk it up and run it across distributed workers. This makes scale-out simple and dynamic on the user's end.\n",
    "\n",
    "* **Lookup tools** are available in Coffea for any corrections that need to be made to physics data. These tools read a variety of correction file formats and turn them into lookup tables.\n",
    "\n",
    "We will go through the first three points within this tutorial. As corrections tend to be experiment-specific, they are outside our scope, but the coffea docs offer some [examples](https://coffeateam.github.io/coffea/notebooks/applying_corrections.html) from a CMS perspective.\n",
    "\n",
    "For the purposes of this tutorial we will be using a data sample converted to a generic ntuple format from a [Powheg+Pythia ttbar dataset](https://opendata.cern.ch/record/19981). It contains 40600 events at 1.3 GB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abffcc4-cc2c-4838-9fad-ee123803f536",
   "metadata": {},
   "source": [
    "## A Motivating Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43990d64-4770-4469-a340-7709b281d6ee",
   "metadata": {},
   "source": [
    "Placeholder. Showcase coffea vs. event loop to motivate why we'd want to use it.\n",
    "* Find a suitable analysis for this.\n",
    "* Maybe show the analysis we'll build through the tutorial, just to also show \"where we'll end up?\"\n",
    "* If we do make a comparison here, then imports/NanoAODSchema warning messages will be here, so they remain here for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c39979-2731-48a8-bd32-ec441b6c4c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.nanoevents import NanoEventsFactory, BaseSchema\n",
    "from coffea import hist\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import uproot\n",
    "\n",
    "# NanoEvents will try to build crossrefs that aren't in our file! Silence this as it's irrelevant for our purposes.\n",
    "NanoAODSchema.warn_missing_crossrefs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ac174-48d3-47b4-9135-357de64027f4",
   "metadata": {},
   "source": [
    "## **Preliminary**: Data with Awkward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f11d5-5f96-4f75-8593-4fb6eb427ee8",
   "metadata": {},
   "source": [
    "As mentioned in the overview, NanoEvents essentially bundles data with physical meaning. We input some ntuple file and we get an awkward array with some added utilities for physics. To follow a Coffea analysis, then, you need some familiarity with awkward. Awkward has a lot of great tutorials to refer to (including the one which preceded this talk), but this preliminary section is intended to show the necessary basics.\n",
    "\n",
    "NanoEvents uses uproot to access data. The data is accessed lazily, so it is not instantiated until it is used. As our file is in an ntuple format, we can open it with the <code>BaseSchema</code> for now for the purposes of exploration. Later, we will use a schema to demonstrate the real power of NanoEvents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94e22a86-596d-418d-aeb5-233a024f7b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events = NanoEventsFactory.from_root('https://xrootd-local.unl.edu:1094/store/user/AGC/FCBEF10A-19D4-E511-83BF-E41D2D08DCA0_merged.root', schemaclass=BaseSchema, treepath='events').events()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d7e136-c980-482a-87d5-f48159d077b8",
   "metadata": {},
   "source": [
    "What does our data look like? Well, it's an awkward array. Each entry in the awkward array corresponds to an event, and each event has various fields that stem from our data. It is a simple command to examine the fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64305403-ccb2-47cd-9a08-4a48a0523926",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numberelectron',\n",
       " 'nelectron_e',\n",
       " 'electron_e',\n",
       " 'nelectron_pt',\n",
       " 'electron_pt',\n",
       " 'nelectron_px',\n",
       " 'electron_px',\n",
       " 'nelectron_py',\n",
       " 'electron_py',\n",
       " 'nelectron_pz',\n",
       " 'electron_pz',\n",
       " 'nelectron_eta',\n",
       " 'electron_eta',\n",
       " 'nelectron_phi',\n",
       " 'electron_phi',\n",
       " 'nelectron_ch',\n",
       " 'electron_ch',\n",
       " 'nelectron_iso',\n",
       " 'electron_iso',\n",
       " 'nelectron_isLoose',\n",
       " 'electron_isLoose',\n",
       " 'nelectron_isMedium',\n",
       " 'electron_isMedium',\n",
       " 'nelectron_isTight',\n",
       " 'electron_isTight',\n",
       " 'nelectron_dxy',\n",
       " 'electron_dxy',\n",
       " 'nelectron_dz',\n",
       " 'electron_dz',\n",
       " 'nelectron_dxyError',\n",
       " 'electron_dxyError',\n",
       " 'nelectron_dzError',\n",
       " 'electron_dzError',\n",
       " 'numGenPart',\n",
       " 'nGenPart_pt',\n",
       " 'GenPart_pt',\n",
       " 'nGenPart_eta',\n",
       " 'GenPart_eta',\n",
       " 'nGenPart_mass',\n",
       " 'GenPart_mass',\n",
       " 'nGenPart_pdgId',\n",
       " 'GenPart_pdgId',\n",
       " 'nGenPart_phi',\n",
       " 'GenPart_phi',\n",
       " 'nGenPart_px',\n",
       " 'GenPart_px',\n",
       " 'nGenPart_py',\n",
       " 'GenPart_py',\n",
       " 'nGenPart_pz',\n",
       " 'GenPart_pz',\n",
       " 'nGenPart_status',\n",
       " 'GenPart_status',\n",
       " 'numberjet',\n",
       " 'njet_e',\n",
       " 'jet_e',\n",
       " 'njet_pt',\n",
       " 'jet_pt',\n",
       " 'njet_px',\n",
       " 'jet_px',\n",
       " 'njet_py',\n",
       " 'jet_py',\n",
       " 'njet_pz',\n",
       " 'jet_pz',\n",
       " 'njet_eta',\n",
       " 'jet_eta',\n",
       " 'njet_phi',\n",
       " 'jet_phi',\n",
       " 'njet_ch',\n",
       " 'jet_ch',\n",
       " 'njet_mass',\n",
       " 'jet_mass',\n",
       " 'njet_btag',\n",
       " 'jet_btag',\n",
       " 'njet_pt_uncorr',\n",
       " 'jet_pt_uncorr',\n",
       " 'met_e',\n",
       " 'met_pt',\n",
       " 'met_px',\n",
       " 'met_py',\n",
       " 'met_phi',\n",
       " 'met_significance',\n",
       " 'met_rawpt',\n",
       " 'met_rawphi',\n",
       " 'met_rawe',\n",
       " 'numbermuon',\n",
       " 'nmuon_e',\n",
       " 'muon_e',\n",
       " 'nmuon_pt',\n",
       " 'muon_pt',\n",
       " 'nmuon_px',\n",
       " 'muon_px',\n",
       " 'nmuon_py',\n",
       " 'muon_py',\n",
       " 'nmuon_pz',\n",
       " 'muon_pz',\n",
       " 'nmuon_eta',\n",
       " 'muon_eta',\n",
       " 'nmuon_phi',\n",
       " 'muon_phi',\n",
       " 'nmuon_ch',\n",
       " 'muon_ch',\n",
       " 'nmuon_isSoft',\n",
       " 'muon_isSoft',\n",
       " 'nmuon_isTight',\n",
       " 'muon_isTight',\n",
       " 'nmuon_dxy',\n",
       " 'muon_dxy',\n",
       " 'nmuon_dz',\n",
       " 'muon_dz',\n",
       " 'nmuon_dxyError',\n",
       " 'muon_dxyError',\n",
       " 'nmuon_dzError',\n",
       " 'muon_dzError',\n",
       " 'nmuon_pfreliso03all',\n",
       " 'muon_pfreliso03all',\n",
       " 'nmuon_pfreliso04all',\n",
       " 'muon_pfreliso04all',\n",
       " 'nmuon_jetidx',\n",
       " 'muon_jetidx',\n",
       " 'nmuon_genpartidx',\n",
       " 'muon_genpartidx',\n",
       " 'numberphoton',\n",
       " 'nphoton_e',\n",
       " 'photon_e',\n",
       " 'nphoton_pt',\n",
       " 'photon_pt',\n",
       " 'nphoton_px',\n",
       " 'photon_px',\n",
       " 'nphoton_py',\n",
       " 'photon_py',\n",
       " 'nphoton_pz',\n",
       " 'photon_pz',\n",
       " 'nphoton_eta',\n",
       " 'photon_eta',\n",
       " 'nphoton_phi',\n",
       " 'photon_phi',\n",
       " 'nphoton_ch',\n",
       " 'photon_ch',\n",
       " 'nphoton_chIso',\n",
       " 'photon_chIso',\n",
       " 'nphoton_nhIso',\n",
       " 'photon_nhIso',\n",
       " 'nphoton_phIso',\n",
       " 'photon_phIso',\n",
       " 'nphoton_isLoose',\n",
       " 'photon_isLoose',\n",
       " 'nphoton_isMedium',\n",
       " 'photon_isMedium',\n",
       " 'nphoton_isTight',\n",
       " 'photon_isTight',\n",
       " 'nPV_chi2',\n",
       " 'PV_chi2',\n",
       " 'nPV_ndof',\n",
       " 'PV_ndof',\n",
       " 'PV_npvs',\n",
       " 'PV_npvsGood',\n",
       " 'nPV_x',\n",
       " 'PV_x',\n",
       " 'nPV_y',\n",
       " 'PV_y',\n",
       " 'nPV_z',\n",
       " 'PV_z',\n",
       " 'numbertau',\n",
       " 'ntau_e',\n",
       " 'tau_e',\n",
       " 'ntau_pt',\n",
       " 'tau_pt',\n",
       " 'ntau_px',\n",
       " 'tau_px',\n",
       " 'ntau_py',\n",
       " 'tau_py',\n",
       " 'ntau_pz',\n",
       " 'tau_pz',\n",
       " 'ntau_eta',\n",
       " 'tau_eta',\n",
       " 'ntau_phi',\n",
       " 'tau_phi',\n",
       " 'ntau_ch',\n",
       " 'tau_ch',\n",
       " 'ntau_mass',\n",
       " 'tau_mass',\n",
       " 'ntau_decaymode',\n",
       " 'tau_decaymode',\n",
       " 'ntau_iddecaymode',\n",
       " 'tau_iddecaymode',\n",
       " 'ntau_idisoraw',\n",
       " 'tau_idisoraw',\n",
       " 'ntau_idisovloose',\n",
       " 'tau_idisovloose',\n",
       " 'ntau_idisoloose',\n",
       " 'tau_idisoloose',\n",
       " 'ntau_idisomedium',\n",
       " 'tau_idisomedium',\n",
       " 'ntau_idisotight',\n",
       " 'tau_idisotight',\n",
       " 'ntau_idantieletight',\n",
       " 'tau_idantieletight',\n",
       " 'ntau_idantimutight',\n",
       " 'tau_idantimutight',\n",
       " 'numbertrigobj',\n",
       " 'ntrigobj_e',\n",
       " 'trigobj_e',\n",
       " 'ntrigobj_pt',\n",
       " 'trigobj_pt',\n",
       " 'ntrigobj_px',\n",
       " 'trigobj_px',\n",
       " 'ntrigobj_py',\n",
       " 'trigobj_py',\n",
       " 'ntrigobj_pz',\n",
       " 'trigobj_pz',\n",
       " 'ntrigobj_eta',\n",
       " 'trigobj_eta',\n",
       " 'ntrigobj_phi',\n",
       " 'trigobj_phi']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d5996-3ab1-465a-a533-202d39947b8a",
   "metadata": {},
   "source": [
    "It is also fairly simple (with Awkward) to check how many events we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd8fc00a-02bd-4418-9fbe-b4a572fbe159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40600"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.size(events, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2a3837-a741-4160-a182-9967db394538",
   "metadata": {},
   "source": [
    "Of course, each field of an event might have a variable amount of objects within it. We might have 0, 1, 2, or any n number of muons in a single event. This is what is meant by \"jagged\" data. If we look at muons in particular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c790d37-24ab-4195-b8c0-75ce7172384b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [[5.9, 4.44, 2.29, ... [43.6, 40.7]] type='40600 * var * float32[paramete...'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.muon_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb8c44c7-5a7c-4e86-a6c4-1ca39be84abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [[5.9, 4.44, 2.29, 0.761], []] type='2 * var * float32[parameters={\"__doc...'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.muon_pt[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd7c1d4-0220-4e0e-b36c-d6e23a2587cf",
   "metadata": {},
   "source": [
    "Looking at <code>events.muon_pt</code> we clearly see this jagged structure. It is an array of size 40600, but each element of the array is itself a (sub)array of variable length. The picture is clarified if we look at a subset of <code>events.muon_pt</code> such that we don't run into the print length cut-off. The first event has 4 muon_pts (and thus 4 muons) while the second event has none (it is an empty subarray).\n",
    "\n",
    "To drive the point home, let's count up the number of muons across all of our events. <code>ak.num</code> can be used to tell us how many muons are in each event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6702024b-e035-4435-a9be-3e3866d01d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [4, 0, 1, 0, 3, 4, ... 0, 7, 6, 1, 2, 2] type='40600 * int64'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.num(events.muon_pt, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9678e7-d52d-47f3-91db-83196371641d",
   "metadata": {},
   "source": [
    "A quick note about axes in Awkward: 0 is always the shallowest, while -1 is the deepest. In other words, <code>axis=0</code> would tell us the number of subarrays (events), while <code>axis=-1</code> sums up the number of muons within each subarray. Then we can just sum up these counts to get the number of muons across all events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de72dea0-6a8b-4fbf-8ab7-73afcb1505a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74656"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.sum(ak.num(events.muon_pt, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d36cbc-7a9b-4ed6-827e-b7c2c3b27162",
   "metadata": {},
   "source": [
    "So the number of muons is clearly not the same as the number of events. \n",
    "\n",
    "Now that we know how to access data, we can manipulate it as we desire in the standard awkward way. Most cuts in columnar analysis are achieved through masking. Shortly, a mask is a Boolean array which is generated by performing a conditional on a data array. For example, if we want only muons with a p<sub>T</sub> > 10, our mask would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c57d1ba-4130-4a44-934a-2110ff75146c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [[False, False, False, ... [True, True]] type='40600 * var * bool'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.muon_pt > 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a0029-a088-43e6-9232-4fdbb52d2371",
   "metadata": {},
   "source": [
    "Then, we can apply the mask to our data. This will pick out only the elements of our data which correspond to a <code>True</code>. The data and the mask thus must have the same shape up to the depth of the selection. Since we're making a selection on muons, the mask must have the exact same shape as the <code>events.muon_pt</code> data. Conversely, the shape of the output array will differ from the data and mask arrays since we want to \"throw out\" the data that doesn't meet our requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "672f9542-4002-4776-a571-e1d4c83228c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Input:',\n",
       " <Array [[5.9, 4.44, 2.29, ... [43.6, 40.7]] type='40600 * var * float32[paramete...'>,\n",
       " 'Output (pT > 10):',\n",
       " <Array [[], [], [14.1], ... [], [43.6, 40.7]] type='40600 * var * float32[parame...'>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Input:', events.muon_pt, 'Output (pT > 10):', events.muon_pt[events.muon_pt > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9c02d1-64ba-4f11-b3a7-2b3c89926bac",
   "metadata": {},
   "source": [
    "Note that we still have 40600 subarrays, as we still have 40600 events; we only did a selection on muons. If an event had a muon which didn't meet the cut, then that event just has an empty subarray now.\n",
    "\n",
    "Compare the output array to our original data array. The first muons, with p<sub>T</sub> < 10, are no longer present in the array. We'd expect to have fewer muons overall. Let's take another count!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1d9f811-fd3f-46c6-980d-2bd446f624e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20504"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.sum(ak.num(events.muon_pt[events.muon_pt > 10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f9673-c9bd-4d1a-8534-d1e47a4efaef",
   "metadata": {},
   "source": [
    "Conversely, the set of muons whose pT is less than 10 can also be examined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3570924-3113-48b4-9ca8-729b8205171d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [[5.9, 4.44, 2.29, 0.761, ... 2.64], []] type='40600 * var * float32[para...'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.muon_pt[events.muon_pt < 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096dc8fa-db11-4e9f-9847-73b59a36664d",
   "metadata": {},
   "source": [
    "Here, we see the first muons *are* present, as we'd expect. Doing some quick algebra, we'd expect this array to be 74656 - 20504 = 54152 elements in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41234138-1d82-4b11-be14-92c137608051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54152"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.sum(ak.num(events.muon_pt[events.muon_pt < 10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb7edc6-cbeb-465b-a3f7-af0d6c62fd85",
   "metadata": {},
   "source": [
    "## **NanoEvents**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea69bdd-7e37-41b2-a5a7-4884af78ac37",
   "metadata": {},
   "source": [
    "We now turn our attention to NanoEvents. While it's certainly possible to access and manipulate data strictly with awkward, NanoEvents schemas make data much nicer to work with. You can make a schema to work with your particular analysis, or you can use one of the existing schemas if you use common file formats (e.g., NanoAOD).\n",
    "\n",
    "For the purposes of this tutorial, we have made a simple schema whose features we shall conflate with the default awkward behavior. Let's examine that behavior first. A good starting point is taking an inventory of our branches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9343cc44-7ef9-46b0-a982-d548a77fe250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numberelectron',\n",
       " 'nelectron_e',\n",
       " 'electron_e',\n",
       " 'nelectron_pt',\n",
       " 'electron_pt',\n",
       " 'nelectron_px',\n",
       " 'electron_px',\n",
       " 'nelectron_py',\n",
       " 'electron_py',\n",
       " 'nelectron_pz',\n",
       " 'electron_pz',\n",
       " 'nelectron_eta',\n",
       " 'electron_eta',\n",
       " 'nelectron_phi',\n",
       " 'electron_phi',\n",
       " 'nelectron_ch',\n",
       " 'electron_ch',\n",
       " 'nelectron_iso',\n",
       " 'electron_iso',\n",
       " 'nelectron_isLoose',\n",
       " 'electron_isLoose',\n",
       " 'nelectron_isMedium',\n",
       " 'electron_isMedium',\n",
       " 'nelectron_isTight',\n",
       " 'electron_isTight',\n",
       " 'nelectron_dxy',\n",
       " 'electron_dxy',\n",
       " 'nelectron_dz',\n",
       " 'electron_dz',\n",
       " 'nelectron_dxyError',\n",
       " 'electron_dxyError',\n",
       " 'nelectron_dzError',\n",
       " 'electron_dzError',\n",
       " 'numGenPart',\n",
       " 'nGenPart_pt',\n",
       " 'GenPart_pt',\n",
       " 'nGenPart_eta',\n",
       " 'GenPart_eta',\n",
       " 'nGenPart_mass',\n",
       " 'GenPart_mass',\n",
       " 'nGenPart_pdgId',\n",
       " 'GenPart_pdgId',\n",
       " 'nGenPart_phi',\n",
       " 'GenPart_phi',\n",
       " 'nGenPart_px',\n",
       " 'GenPart_px',\n",
       " 'nGenPart_py',\n",
       " 'GenPart_py',\n",
       " 'nGenPart_pz',\n",
       " 'GenPart_pz',\n",
       " 'nGenPart_status',\n",
       " 'GenPart_status',\n",
       " 'numberjet',\n",
       " 'njet_e',\n",
       " 'jet_e',\n",
       " 'njet_pt',\n",
       " 'jet_pt',\n",
       " 'njet_px',\n",
       " 'jet_px',\n",
       " 'njet_py',\n",
       " 'jet_py',\n",
       " 'njet_pz',\n",
       " 'jet_pz',\n",
       " 'njet_eta',\n",
       " 'jet_eta',\n",
       " 'njet_phi',\n",
       " 'jet_phi',\n",
       " 'njet_ch',\n",
       " 'jet_ch',\n",
       " 'njet_mass',\n",
       " 'jet_mass',\n",
       " 'njet_btag',\n",
       " 'jet_btag',\n",
       " 'njet_pt_uncorr',\n",
       " 'jet_pt_uncorr',\n",
       " 'met_e',\n",
       " 'met_pt',\n",
       " 'met_px',\n",
       " 'met_py',\n",
       " 'met_phi',\n",
       " 'met_significance',\n",
       " 'met_rawpt',\n",
       " 'met_rawphi',\n",
       " 'met_rawe',\n",
       " 'numbermuon',\n",
       " 'nmuon_e',\n",
       " 'muon_e',\n",
       " 'nmuon_pt',\n",
       " 'muon_pt',\n",
       " 'nmuon_px',\n",
       " 'muon_px',\n",
       " 'nmuon_py',\n",
       " 'muon_py',\n",
       " 'nmuon_pz',\n",
       " 'muon_pz',\n",
       " 'nmuon_eta',\n",
       " 'muon_eta',\n",
       " 'nmuon_phi',\n",
       " 'muon_phi',\n",
       " 'nmuon_ch',\n",
       " 'muon_ch',\n",
       " 'nmuon_isSoft',\n",
       " 'muon_isSoft',\n",
       " 'nmuon_isTight',\n",
       " 'muon_isTight',\n",
       " 'nmuon_dxy',\n",
       " 'muon_dxy',\n",
       " 'nmuon_dz',\n",
       " 'muon_dz',\n",
       " 'nmuon_dxyError',\n",
       " 'muon_dxyError',\n",
       " 'nmuon_dzError',\n",
       " 'muon_dzError',\n",
       " 'nmuon_pfreliso03all',\n",
       " 'muon_pfreliso03all',\n",
       " 'nmuon_pfreliso04all',\n",
       " 'muon_pfreliso04all',\n",
       " 'nmuon_jetidx',\n",
       " 'muon_jetidx',\n",
       " 'nmuon_genpartidx',\n",
       " 'muon_genpartidx',\n",
       " 'numberphoton',\n",
       " 'nphoton_e',\n",
       " 'photon_e',\n",
       " 'nphoton_pt',\n",
       " 'photon_pt',\n",
       " 'nphoton_px',\n",
       " 'photon_px',\n",
       " 'nphoton_py',\n",
       " 'photon_py',\n",
       " 'nphoton_pz',\n",
       " 'photon_pz',\n",
       " 'nphoton_eta',\n",
       " 'photon_eta',\n",
       " 'nphoton_phi',\n",
       " 'photon_phi',\n",
       " 'nphoton_ch',\n",
       " 'photon_ch',\n",
       " 'nphoton_chIso',\n",
       " 'photon_chIso',\n",
       " 'nphoton_nhIso',\n",
       " 'photon_nhIso',\n",
       " 'nphoton_phIso',\n",
       " 'photon_phIso',\n",
       " 'nphoton_isLoose',\n",
       " 'photon_isLoose',\n",
       " 'nphoton_isMedium',\n",
       " 'photon_isMedium',\n",
       " 'nphoton_isTight',\n",
       " 'photon_isTight',\n",
       " 'nPV_chi2',\n",
       " 'PV_chi2',\n",
       " 'nPV_ndof',\n",
       " 'PV_ndof',\n",
       " 'PV_npvs',\n",
       " 'PV_npvsGood',\n",
       " 'nPV_x',\n",
       " 'PV_x',\n",
       " 'nPV_y',\n",
       " 'PV_y',\n",
       " 'nPV_z',\n",
       " 'PV_z',\n",
       " 'numbertau',\n",
       " 'ntau_e',\n",
       " 'tau_e',\n",
       " 'ntau_pt',\n",
       " 'tau_pt',\n",
       " 'ntau_px',\n",
       " 'tau_px',\n",
       " 'ntau_py',\n",
       " 'tau_py',\n",
       " 'ntau_pz',\n",
       " 'tau_pz',\n",
       " 'ntau_eta',\n",
       " 'tau_eta',\n",
       " 'ntau_phi',\n",
       " 'tau_phi',\n",
       " 'ntau_ch',\n",
       " 'tau_ch',\n",
       " 'ntau_mass',\n",
       " 'tau_mass',\n",
       " 'ntau_decaymode',\n",
       " 'tau_decaymode',\n",
       " 'ntau_iddecaymode',\n",
       " 'tau_iddecaymode',\n",
       " 'ntau_idisoraw',\n",
       " 'tau_idisoraw',\n",
       " 'ntau_idisovloose',\n",
       " 'tau_idisovloose',\n",
       " 'ntau_idisoloose',\n",
       " 'tau_idisoloose',\n",
       " 'ntau_idisomedium',\n",
       " 'tau_idisomedium',\n",
       " 'ntau_idisotight',\n",
       " 'tau_idisotight',\n",
       " 'ntau_idantieletight',\n",
       " 'tau_idantieletight',\n",
       " 'ntau_idantimutight',\n",
       " 'tau_idantimutight',\n",
       " 'numbertrigobj',\n",
       " 'ntrigobj_e',\n",
       " 'trigobj_e',\n",
       " 'ntrigobj_pt',\n",
       " 'trigobj_pt',\n",
       " 'ntrigobj_px',\n",
       " 'trigobj_px',\n",
       " 'ntrigobj_py',\n",
       " 'trigobj_py',\n",
       " 'ntrigobj_pz',\n",
       " 'trigobj_pz',\n",
       " 'ntrigobj_eta',\n",
       " 'trigobj_eta',\n",
       " 'ntrigobj_phi',\n",
       " 'trigobj_phi']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uproot\n",
    "branches = uproot.open(\"https://xrootd-local.unl.edu:1094/store/user/AGC/FCBEF10A-19D4-E511-83BF-E41D2D08DCA0_merged.root\")['events']\n",
    "branches.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac5e87-4466-4dfb-8a45-9df5b22f41f8",
   "metadata": {},
   "source": [
    "That's a mouthful. Let's narrow our focus to the muon branches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f952a19d-3f1d-4452-b0a0-b3cbd1d5bcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbermuon\n",
      "nmuon_e\n",
      "muon_e\n",
      "nmuon_pt\n",
      "muon_pt\n",
      "nmuon_px\n",
      "muon_px\n",
      "nmuon_py\n",
      "muon_py\n",
      "nmuon_pz\n",
      "muon_pz\n",
      "nmuon_eta\n",
      "muon_eta\n",
      "nmuon_phi\n",
      "muon_phi\n",
      "nmuon_ch\n",
      "muon_ch\n",
      "nmuon_isSoft\n",
      "muon_isSoft\n",
      "nmuon_isTight\n",
      "muon_isTight\n",
      "nmuon_dxy\n",
      "muon_dxy\n",
      "nmuon_dz\n",
      "muon_dz\n",
      "nmuon_dxyError\n",
      "muon_dxyError\n",
      "nmuon_dzError\n",
      "muon_dzError\n",
      "nmuon_pfreliso03all\n",
      "muon_pfreliso03all\n",
      "nmuon_pfreliso04all\n",
      "muon_pfreliso04all\n",
      "nmuon_jetidx\n",
      "muon_jetidx\n",
      "nmuon_genpartidx\n",
      "muon_genpartidx\n"
     ]
    }
   ],
   "source": [
    "for branch in branches.keys():\n",
    "    if 'muon' in branch:\n",
    "        print(branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11330d3d-7206-4a7c-8d96-47abd00b3e35",
   "metadata": {},
   "source": [
    "By default, uproot treats all of the muon branches as distinct fields with distinct data. The <code>BaseSchema</code> within NanoEvents functions similarly. But this data is not independent! For one, we would expect the size of all of the <code>muon_*</code> subarrays to be the same (each muon has one of each field, each event has the same number of muons). Using a NanoEvents schema, we can clean our data up a little bit by nesting all of the muon fields beneath a common <code>muon</code> object. This is precisely what we have done in our schema:\n",
    "\n",
    "* Get the schema working, then continue here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05706bd9-dc43-4272-b492-254edb354c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#events = factory with new schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3b83bd4-d51f-4381-a847-6ba9059b2de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#events.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19cac373-8e48-48ee-84a9-0a32b111d752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#events.Muon.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0390ca-1ccd-4af5-91c6-ac99b06b4eda",
   "metadata": {},
   "source": [
    "We can, of course, do similar nesting to other fields within our events array. This will make the surface-level view more compact and navigable. But there are also other benefits when we turn our attention to another feature of schemas: physics methods. We now have an <code>events.muon</code> object. Nominally, it serves as a category for our nesting structure, but it would make physical sense to treat it as a LorentzVector. This behavior has indeed been built into our new schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4d6b3b26-6f7c-40fb-9f99-37a1a1b84b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(events.muon[0] + events.muon[1]).pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3894475c-ba49-4e1f-9e4c-ff60f1459b4a",
   "metadata": {},
   "source": [
    "One other implication of this feature is that, in addition to the fields explicitly mentioned under the MuonArray, we can also access other LorentzVector formulations with NanoEvents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d0fab38b-d17a-453e-a993-05682a1bb481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#events.muon.x, events.muon.y, events.muon.z, events.muon.mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe9b7b0-a051-4acd-87ff-05d4ff667bce",
   "metadata": {},
   "source": [
    "And we have the standard LorentzVector methods defined, such as delta_r for computing the distance between two four-vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "931efd9b-e78c-407a-81e2-ff19e96ecf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#events.muon[0].delta_r(events.muon[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f4316c-76ef-446e-86d2-193b521bd6b9",
   "metadata": {},
   "source": [
    "** If possible, we should add examples of cross-references here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d1d84-74ce-4b31-9d59-0564dcfef242",
   "metadata": {},
   "source": [
    "## **Hists**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b5147-8310-44f8-97ef-b585c85443a5",
   "metadata": {},
   "source": [
    "NanoEvents has given us data which we can access with the appropriate physics imposed. It's only natural that we now move on to plotting that data. Let's consider everybody's favorite simple example: plotting the mass of the Z boson based on the dilepton mass of opposite-charge, same-flavor lepton pairs. This should give us a peak at ~91.12, as many such pairs result from Z decays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61ef3c19-dd80-425d-9db5-2c479f88dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since they're same-flavor, we can just find dimuons and dielectrons independently. Make sure they're opposite charge and that each event has two leptons.\n",
    "#dimuons = events.muon[(ak.num(events.muon, axis=1) == 2) & (ak.sum(events.muon.charge, axis=1) == 0)]\n",
    "#dielectrons = events.electron[(ak.num(events.electron, axis=1) == 2) & (ak.sum(events.electron.charge, axis=1) == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0401964-dd09-41e2-b803-a7806f1d0747",
   "metadata": {},
   "source": [
    "Our <code>dimuons</code> array should now contain only opposite-charge muon pairs and our <code>dielectrons</code> opposite-charge electron pairs. Let's check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "89c8dae6-9adb-4bc3-9f5d-96936c4e6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimuons, dielectrons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe78f4d-aab3-4bd3-bbd4-0b9e360cd89f",
   "metadata": {},
   "source": [
    "Note that the masks performed a cut at the event level rather than the muon level. We have fewer events, but the same amount of leptons in each event (in the events that we kept). That means we've lost the connection between muons and electrons - they've been downselected and it is not the case that the 1st subarray in our electron array is the same event as the 1st subarray in our muon array. This isn't a problem since we're handling the two independently, but there are ways to handle such a selection without downselection if such indexing needs to be preserved.\n",
    "\n",
    "All we need now is the dilepton mass. Awkward arrays can be indexed in a similar way as numpy array, so <code>dimuons[:, 0]</code> will select the first muon in every <code>dimuon</code> event. Recall that NanoEvents allows us to treat mathematical operations on the muon array level as LorentzVector objects. The same goes for our electrons array, of course. That makes our life easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea1eb5b0-7d6e-4c80-aa7c-986265117200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mumu_mass = (dimuons[:, 0] + dimuons[:, 1]).mass\n",
    "#ee_mass = (dielectrons[:, 0] + dielectrons[:, 1]).mass\n",
    "\n",
    "#mumu_mass, ee_mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a361ef-846e-447c-937d-56abb122ebf2",
   "metadata": {},
   "source": [
    "We've effectively collapsed our subarrays by finding the mass of the pairs, so now we have a flat array. It is of the same size (respectively) as our dimuons and dielectrons arrays above. We now have our data!\n",
    "\n",
    "What else do we need for plotting? Well, a histogram is essentially a way to reduce our data. We can't just plot every value of dimuon mass, so we divide up our range of masses into n bins across some reasonable range. Thus, we need to define the mapping for our reduction; defining the number of bins and the range is sufficient for this.\n",
    "\n",
    "In our case, let's plot 50 bins between values of 20 and 150. This removes anomalously low-mass data at the lower end, and merely cuts off a shrinking tail on the higher end. Because a histogram can contain an arbitrary amount of bins (in other words, dimensions), we also need to give our bin a label (which becomes its reference in our code) and a name (which is the name of the axis that users see when the histogram is plotted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d9bf9bb7-db03-475a-bb5f-484003bfae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ll_bin = hist.Bin(label=\"dilep_mass\", name=\"$Dilepton Mass$\", n_or_arr=50, lo=20, hi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b35d1b-ff9e-4f73-9851-977130248f84",
   "metadata": {},
   "source": [
    "We are still not *yet* ready to plot. We have two masses we'd like to plot, and it doesn't make much sense to throw ee masses into the same bins as $\\mu\\mu$ masses. We want to keep these separate. We do so by introducing a categorical axis. Another example of when we might use a categorical axis is to keep data from different datasets separate, though in our case we're only working with a single dataset.\n",
    "\n",
    "The definition of a categorical axis follows that of the bin axis, though this time we don't need any sort of reduction. Categories are specified at the point of filling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b06e44e-87cf-4042-a9b7-8b805a6adfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ll_cat = hist.Cat(\"lepton\", \"Lepton Flavor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db5a5fb-d8a8-4532-87e8-bdd6a6e3532a",
   "metadata": {},
   "source": [
    "We finally have all of the ingredients needed for a histogram! All that remains is to mix them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8395f72-65ad-4414-9f32-0a4ef5984e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ll_hist = hist.Hist(\"Counts\", ll_cat, ll_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e3322d-a601-43a5-9d80-bed800c8f480",
   "metadata": {},
   "source": [
    "Fill it with our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80e4096d-e519-4787-a92e-a098bac08ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ll_hist.fill(lepton=\"$\\mu\\mu$\", dilep_mass=mumu_mass)\n",
    "#ll_hist.fill(lepton=\"ee\", dilep_mass=ee_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff40a4a2-4627-42d8-a10e-cc17b2cbe9c6",
   "metadata": {},
   "source": [
    "And plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "249c2ef0-21cc-46a3-a9ce-7df7dbd8b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist.plot1d(ll_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b306f-1550-40fa-bbbb-0227f0c27ebd",
   "metadata": {},
   "source": [
    "## **Processors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515431f-4d6c-4eb8-b355-f2f972f76240",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827c95d-6816-40aa-b623-44249184554d",
   "metadata": {},
   "source": [
    "### Lookup Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bea61a7-4f85-4cb2-b9cd-357c1394780f",
   "metadata": {},
   "source": [
    "### ServiceX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08df1596-1410-4244-b0c9-a5ebbbed00ab",
   "metadata": {},
   "source": [
    "## Acknowledgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f19935-dba1-4f59-adef-1331d3f937c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
